{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiwmiPwAjqRAajhC4Tx1w4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We'll go over an example of how to design and implement an LLM-powered chatbot. This chatbot will be able to have a conversation and remember previous interactions.\n"
      ],
      "metadata": {
        "id": "-wz0X06leFDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a few of the high-level components we'll be working with:\n",
        "\n",
        "- **Chat Models.** The chatbot interface is based around messages rather than raw text, and therefore is best suited to Chat Models rather than text LLMs.\n",
        "- **Prompt Templates,** which simplify the process of assembling prompts that combine default messages, user input, chat history, and (optionally) additional retrieved context.\n",
        "- **Chat History,** which allows a chatbot to \"remember\" past interactions and take them into account when responding to followup questions.\n",
        "- **Debugging and tracing** your application using LangSmith\n",
        "We'll cover how to fit the above components together to create a powerful conversational chatbot."
      ],
      "metadata": {
        "id": "oK8GBWyMeYYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "QR3hHfQQejHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMwPBD2bCl4f"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"Langchain-chatbot\"\n",
        "os.environ[\"COHERE_API_KEY\"] = userdata.get('COHERE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q langchain\n",
        "! pip install -q cohere\n",
        "! pip install -q langchain-community\n"
      ],
      "metadata": {
        "id": "t3vTs8J0CsCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model selection"
      ],
      "metadata": {
        "id": "paiRkfykFmhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -qU langchain-cohere"
      ],
      "metadata": {
        "id": "t0LDwEP5IreN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_cohere import ChatCohere\n",
        "model = ChatCohere(model=\"command-r\")"
      ],
      "metadata": {
        "id": "VmPoSPY5lyDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat Model\n",
        "\n",
        "ChatModels are instances of LangChain \"Runnables\", which means they expose a standard interface for interacting with them. To just simply call the model, we can pass in a list of messages to the .invoke method."
      ],
      "metadata": {
        "id": "z9xawr95G7sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "model.invoke([HumanMessage(content=\"Hi! My name is Ram.\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qM4y6uDDGFj",
        "outputId": "f08fb76f-2d7a-48ac-c2fa-c717ed35d398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hi Ram! It's nice to meet you. How's it going today?\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '82df93df-ed4c-41da-b9b9-374eb7adbc3c', 'token_count': {'input_tokens': 73, 'output_tokens': 16}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '82df93df-ed4c-41da-b9b9-374eb7adbc3c', 'token_count': {'input_tokens': 73, 'output_tokens': 16}}, id='run-9f65dc67-144f-43b4-8d1f-a80cabfcf994-0')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model on its own does not have any concept of state. For example, if you ask a followup question:\n",
        "\n"
      ],
      "metadata": {
        "id": "1QXFA0FCJA9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke([HumanMessage(\"What is my name?\")])"
      ],
      "metadata": {
        "id": "P4opoB2GheW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acdcc2f-c5cc-48ba-8db7-8639b4a90e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I'm sorry, but as an AI chatbot, I don't know your name. The name is something that you did not share with me, and I cannot guess it either. However, if you tell me your name, I'll be happy to address you by it.\", additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9e8baad1-1efe-4efa-9204-174f0b90fa17', 'token_count': {'input_tokens': 71, 'output_tokens': 55}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '9e8baad1-1efe-4efa-9204-174f0b90fa17', 'token_count': {'input_tokens': 71, 'output_tokens': 55}}, id='run-097503b8-d1e4-4882-a842-b256da966290-0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " To make the model to remember, we need to pass the entire conversation history into the model"
      ],
      "metadata": {
        "id": "DcuaPrUWJZMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content =\"Hi! My name is Ram.\"),\n",
        "        AIMessage(content=\"Hello Ram! It's nice to meet you\"),\n",
        "        HumanMessage(content=\"What is my name?\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPztIPdSJIXd",
        "outputId": "6824c7da-af72-4e03-97ce-c68546ae0590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Your name is Ram! You mentioned it at the beginning of our conversation. Nice to meet you, Ram!', additional_kwargs={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7b370ccd-7ecc-45b2-81fd-506c46704fb9', 'token_count': {'input_tokens': 93, 'output_tokens': 22}}, response_metadata={'documents': None, 'citations': None, 'search_results': None, 'search_queries': None, 'is_search_required': None, 'generation_id': '7b370ccd-7ecc-45b2-81fd-506c46704fb9', 'token_count': {'input_tokens': 93, 'output_tokens': 22}}, id='run-3b6b1253-be63-44b2-aafc-47969c225a46-0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we can see that we get a good response!\n",
        "\n",
        "This is the basic idea underpinning a chatbot's ability to interact conversationally. So how do we best implement this?\n",
        "\n"
      ],
      "metadata": {
        "id": "a6XODGwUKA-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Message History"
      ],
      "metadata": {
        "id": "QpOeKEw7KKSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "\n",
        "    return store[session_id]\n",
        "\n",
        "with_message_histroy = RunnableWithMessageHistory(runnable=model,get_session_history=get_session_history)"
      ],
      "metadata": {
        "id": "dCm7bjK-J8tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"123\"}}"
      ],
      "metadata": {
        "id": "2n18zKuGUiAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_histroy.invoke(\n",
        "    [HumanMessage(content=\"Hi! My name is Ram.\")],\n",
        "    config=config,\n",
        ")\n",
        "response.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "gohTTr01Uw-z",
        "outputId": "ab0368c7-5d4c-40f2-c6e2-1b8eb282e5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 9ef51051-45e4-4b1c-82b4-940110b7da4c not found for run 5dd3b138-d5f4-4af6-9948-760382b3f52e. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Ram! It's nice to meet you. How's it going today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_histroy.invoke(\n",
        "    [HumanMessage(content=\"What is my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YeIgDHAPUw8d",
        "outputId": "11e9e3cd-67e5-4f6a-ac02-e6920e017f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run cfe40c63-9079-4cb1-b19a-81692e08ee1c not found for run b742fcba-ac8e-4372-b8eb-0c8e8f4ddc29. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Ram! You mentioned it at the beginning of our conversation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Our chatbot now remembers things about us. If we change the config to reference a different session_id, we can see that it starts the conversation fresh.\n",
        "\n"
      ],
      "metadata": {
        "id": "vhD4rroMVqkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"456\"}}\n",
        "response = with_message_histroy.invoke(\n",
        "    [HumanMessage(content=\"What is my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "4J4YWYENUw6a",
        "outputId": "a09bf4f6-0222-4bec-d73b-60a0bfdd6a3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run e7f6b44c-c219-4b36-ae80-8af370b75c4a not found for run eb9c5438-d0c4-4a30-b35d-d1e801044782. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but as an AI chatbot, I don't know your name. The name is something that you did not share with me, and I cannot guess it either. However, if you tell me your name, I'll be happy to address you by it.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"123\"}}\n",
        "response = with_message_histroy.invoke(\n",
        "    [HumanMessage(content=\"Hi! My name is Ram.\")],\n",
        "    config=config,\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SE8hRvPbUwtp",
        "outputId": "b26679bf-a937-400b-fb6e-fe5f5a49ccbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run b94f3b95-8fae-438f-a941-2d438a54047f not found for run efecac49-b76f-4d43-9aa8-8f2bec51fa5e. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello Ram! It's great to hear from you. Are you named after anyone or is it a name you really like?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt templates"
      ],
      "metadata": {
        "id": "jN6p5-tSWSCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ],
      "metadata": {
        "id": "SRLDH3MmWRUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpfull assistant\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "NJPi9wrGWRPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "3KtAtwJGWRNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\":[\n",
        "            HumanMessage(content=\"Hi! My name is Ram.\")\n",
        "            ]\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "O_bZ_7ekWRLF",
        "outputId": "964f37c5-2d86-46ed-cb35-268bdae70ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi Ram! It's nice to meet you. How's your day been so far?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now wrap this in the same Messages History object as before\n",
        "\n"
      ],
      "metadata": {
        "id": "krdjtPk6ZW-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    runnable=chain,\n",
        "    get_session_history=get_session_history\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"ram11\"}}\n",
        "response = with_message_histroy.invoke(\n",
        "    [HumanMessage(content=\"Hi! My name is Ram.\")],\n",
        "    config=config,\n",
        ")\n",
        "response.content\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "b1HEchBtZYGC",
        "outputId": "94a68411-f52f-4f65-f7d5-be582a842b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run be572598-5bf6-4515-996c-e0ee6ad14d47 not found for run be0cb561-f4c3-488b-b539-af3f19c38cc6. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello Ram! It's lovely to meet you. I hope you're doing well and having a wonderful day. Do you want to talk about anything specific, or just have a general chat?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_histroy.invoke(\n",
        "    [HumanMessage(content=\"What is my name?\")],\n",
        "    config=config,\n",
        ")\n",
        "response.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Qvshkac9aDZ4",
        "outputId": "5337cf08-ed67-45cf-ab8a-f39f77ce0328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run bd833587-46f7-457b-86c5-0a979147dfec not found for run c18007f8-5e23-4428-9b62-e90cfa72ad0c. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Your name is Ram! It's a pleasure to have you here, Ram. Is there anything you would like to talk about?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome! Let's now make our prompt a little bit more complicated. Let's assume that the prompt template now looks something like this:\n",
        "\n"
      ],
      "metadata": {
        "id": "NyH34uErajP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\"),\n",
        "        MessagesPlaceholder(variable_name=\"messages\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | model"
      ],
      "metadata": {
        "id": "8xEOQ64wakev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\":[HumanMessage(content=\"Hi! My name is Ram.\")],\n",
        "        \"language\":\"Spanish\"\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P4LrTt8bakal",
        "outputId": "f9f31a06-0710-4291-fb7c-ad411cb670b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¡Hola, Ram! Me alegra conocerte.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    runnable=chain,\n",
        "    get_session_history=get_session_history,\n",
        "    input_messages_key=\"messages\"\n",
        ")"
      ],
      "metadata": {
        "id": "qRs1hT23akX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc11\"}}"
      ],
      "metadata": {
        "id": "x0ByOQDJakVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\" : [HumanMessage(content=\"Hi! My name is Ram.\")],\n",
        "        \"language\": \"Spanish\"\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "response.content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XL5gTYBhakTj",
        "outputId": "812e9bcc-ec51-42e3-f344-980ecf70fccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 2635ca29-5606-4ae5-9c02-34f0df26e7de not found for run 3a6ed5ee-31ee-4086-8347-97ca759a4307. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'¡Hola, Ram! Me alegra conocerte.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Spanish\"},\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zi51RKQGakRP",
        "outputId": "f1bedcca-7ae2-4b2b-8759-10bcb30837fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 394bd7dd-2adb-43e0-9415-435edf712525 not found for run 2e76b8e6-ba98-4601-ba95-674fb792645c. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tu nombre es Ram. ¡Un nombre muy interesante!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Managing Conversation History"
      ],
      "metadata": {
        "id": "t_MVEbwrWQ3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough"
      ],
      "metadata": {
        "id": "fHn_sc4seSTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_messages(messages, k=10):\n",
        "    return messages[-k:]\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        messages = lambda x: filter_messages(x[\"messages\"])\n",
        "    )\n",
        "    | prompt\n",
        "    | model\n",
        ")"
      ],
      "metadata": {
        "id": "ifjTQ0FjeSQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    HumanMessage(content=\"hi! I'm Ram\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]"
      ],
      "metadata": {
        "id": "vWQmYV52eSOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "71eR-vMceSHc",
        "outputId": "85433de9-4ec0-4bb3-f35b-f413b3496f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I can't help you with that. You haven't introduced yourself yet! Who would you like your name to be?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my fav ice cream\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a1GMJZyBeSFX",
        "outputId": "d52d0ebe-25cb-48d0-e9af-da16b9e36cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You seem to like vanilla ice cream! But to confirm, what is your favorite ice cream flavor?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n",
        "\n",
        "config = {\"configurable\": {\"session_id\": \"abc20\"}}"
      ],
      "metadata": {
        "id": "BFfeVqP-eSDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "iTEAEB7UiB17",
        "outputId": "11cc6b48-ad11-4f0f-cb0d-dd58eb2aec1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run fb4994c3-62ee-4416-b707-0fe0e80c7280 not found for run c398775d-b2c9-4a80-b268-39834842d259. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I can't help you with that as you haven't mentioned your name yet. If you'd like, I could help you come up with some name suggestions. I've helped other users with this in the past and it's quite fun! There are also some cool baby name websites we could use. Would you like me to give you some name suggestions?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = with_message_history.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"whats my favorite ice cream?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "8XSVZSJYiHBI",
        "outputId": "0fa43d85-aa3d-4c21-923d-ebfea4104dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run b41d510d-fc67-4aaa-a0b5-ba1f5fe52b8c not found for run 0492f512-42f7-4ef3-8c0c-c7c984e3e9ce. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Since I don't know who you are, I don't know your favorite ice cream flavor. However, some popular ice cream flavors include chocolate, vanilla, and strawberry. Do you want to know anything else about ice cream?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming"
      ],
      "metadata": {
        "id": "lCuYUDk0ikUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
        "config = {\"configurable\": {\"session_id\": \"abc15\"}}\n",
        "for r in with_message_history.stream(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"hi! I'm todd. tell me a joke\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        "):\n",
        "    print(r.content, end=\"|\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csOnCH8biG8s",
        "outputId": "ec7bd2b8-c9cc-4c38-f692-b23a319ed355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.tracers.core:Parent run 250927fc-a33a-410d-b71b-8186a6e6474f not found for run cc9116ed-3582-4aa7-90b8-8d44feb113e5. Treating as a root run.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello| Todd|!| This| one|'s| for| you|:|\n",
            "\n",
            "What| do| you| call| a| factory| that| makes| distinctly| average| products|?| \n",
            "\n",
            "An| adequate| factory|!|\n",
            "\n",
            "Have| a| great| day|,| Todd|!|Hello Todd! This one's for you:\n",
            "\n",
            "What do you call a factory that makes distinctly average products? \n",
            "\n",
            "An adequate factory!\n",
            "\n",
            "Have a great day, Todd!|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0USweloiG6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IFbPHDpkiG0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3G_t4UPsiGxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zMsalK3tKJUe"
      }
    }
  ]
}